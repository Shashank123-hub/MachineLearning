{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social Distancing Tool(ML & Deep learning).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_FYBIE24ABBpHLwTmXXNqvDbblPt_VV2",
      "authorship_tag": "ABX9TyPHlp/i/3/+2D1lIMvEIhlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank123-hub/MachineLearning/blob/master/Social_Distancing_Tool(ML_%26_Deep_learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsdcfFhx2nes",
        "colab_type": "text"
      },
      "source": [
        "#**Project topic : Building a social distancing tool**# \n",
        "\n",
        "This is an interesting model that can potentially detect the real-time location of an individual, and return a warning if the distance between two people is dangerously close. As we know during this current epidemic, social distancing has emerged an effective and important solution in keeping people safe and contolling the spread of this deadly disease.\n",
        "\n",
        "Not only that, the WHO itself has advised each and every notion to adopt the policy of Social Distancing to control the spread of this deadly pathogen at least until a vaccine has been found."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGpxEm9y2naH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "For this , we'll be using the concept of ***Object Detection*** and a open-source library for the same purpose known as ***Detectron-2***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZBUNT2GxI1s",
        "colab_type": "text"
      },
      "source": [
        "#**Step 1 : Installing dependencies**#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kscEu5YewMGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "# opencv is pre-installed on colab\n",
        "!pip install -U torch==1.5 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "!gcc --version\n",
        "\n",
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/index.html\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybTMQyMkzrfy",
        "colab_type": "text"
      },
      "source": [
        "#**Step 1(b) : Importing libraries**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iMqxB6Wzs8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "#importing common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#importing common detectron2 utilities \n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95hB38p3Zgf",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2 : Importing the input video from google drive**#\n",
        "\n",
        "First of all, we'll mount the Google Drive to the Google Colaboratory and then read the video frame by frame for the purpose of object detection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXFDRlD7FPMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/GDrive')\n",
        "%cd /GDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9bCGrbbI4cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSU57viE3aH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!mkdir frames/\n",
        "\n",
        "!rm -r frames/*\n",
        "\n",
        "\n",
        "#specify path to video\n",
        "video = \"GDrive/My Drive/sample.mp4\"\n",
        "\n",
        "#capture video\n",
        "cap = cv2.VideoCapture(video)\n",
        "cnt=0\n",
        "\n",
        "# Check if video file is opened successfully\n",
        "if (cap.isOpened()== False): \n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "ret,first_frame = cap.read()\n",
        "\n",
        "#Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "    \n",
        "  # Capture frame-by-frame\n",
        "  ret, frame = cap.read()\n",
        "     \n",
        "  if ret == True:\n",
        "\n",
        "    #save each frame to folder        \n",
        "    cv2.imwrite('frames/'+str(cnt)+'.png', frame)\n",
        "    cnt=cnt+1\n",
        "    if(cnt==750):\n",
        "      break\n",
        "\n",
        "  # Break the loop\n",
        "  else: \n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LHUZQJ9CceQ",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2(b) : Checking frame rate of the video**#\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljmydxGpCdAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(FPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if4JAxxjUh6M",
        "colab_type": "text"
      },
      "source": [
        "#**Step 3 : Download the pre-trained model for object detection**#\n",
        "\n",
        "Download the pre-trained model from Detectron 2's model zoo and the model is ready for inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phRGyag8UiWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9  # set threshold for this model\n",
        "\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa9n7E9zUi_q",
        "colab_type": "text"
      },
      "source": [
        "#**Step 3(b) : Reading the image and passing to model for prediction**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TXyXNjSUjh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read an image\n",
        "img = cv2.imread(\"frames/100.png\")\n",
        "\n",
        "#pass to the model\n",
        "outputs = predictor(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl5-6bx6WjYm",
        "colab_type": "text"
      },
      "source": [
        "#**Step 4 : Drawing the prediction on the image**#\n",
        "\n",
        "We can Visualize to draw the predictions on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izOcLdnxWkGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqIXYr-jbCIu",
        "colab_type": "text"
      },
      "source": [
        "#**Step 4(b) : Understanding the objects present in an image**#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMbcadqnbCrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=outputs['instances'].pred_classes.cpu().numpy()\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugdCpFK0bDS_",
        "colab_type": "text"
      },
      "source": [
        "#**Step 4(c) : These are the bounding boxes of an object**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVXvAq9ibDqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "print(bbox)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNPJVDHobD3g",
        "colab_type": "text"
      },
      "source": [
        "**Since,there are different object in the image, let's identify classes and bounding boxes related to only the people :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltBdpQ_AbEIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#identity only persons \n",
        "ind = np.where(classes==0)[0]\n",
        "\n",
        "#identify bounding box of only persons\n",
        "person=bbox[ind]\n",
        "\n",
        "#total no. of persons\n",
        "num= len(person)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56CCeNzujxtP",
        "colab_type": "text"
      },
      "source": [
        "**Understanding the format of the bounding box :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUjO8c2KcQUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1,y1,x2,y2 = person[0]\n",
        "print(x1,y1,x2,y2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfBKq8XIkJRc",
        "colab_type": "text"
      },
      "source": [
        "**Draw a bounding box for one of the people :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIy9gzFcU67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = cv2.imread('frames/100.png')\n",
        "_ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv-vKWE6kVYw",
        "colab_type": "text"
      },
      "source": [
        "#**Step 5 : Identifying the safe and appropriate distance among the people in the set of frames**#\n",
        "\n",
        "Once we know the bounding boxes for each person, we can identify and compute the distance between two people.\n",
        "\n",
        "Here, we have chosen the bottom centre of the rectangle for representing each person to measure the distance accurately. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT0OGiMNckoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute center \n",
        "x_center = int((x1+x2)/2)\n",
        "y_center = int(y2)\n",
        "\n",
        "center = (x_center, y_center)\n",
        "\n",
        "_ = cv2.circle(img, center, 5, (255, 0, 0), -1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gOYsAqjlpyM",
        "colab_type": "text"
      },
      "source": [
        "**A function that returns the bottom center of every bounding box :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vp76W_qJckwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define a function which return the bottom center of every bbox\n",
        "def mid_point(img,person,idx):\n",
        "  #get the coordinates\n",
        "  x1,y1,x2,y2 = person[idx]\n",
        "  _ = cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "  \n",
        "  #compute bottom center of bbox\n",
        "  x_mid = int((x1+x2)/2)\n",
        "  y_mid = int(y2)\n",
        "  mid   = (x_mid,y_mid)\n",
        "  \n",
        "  _ = cv2.circle(img, mid, 5, (0, 0, 255), -1)\n",
        "  cv2.putText(img, str(idx), mid, cv2.FONT_HERSHEY_SIMPLEX,1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "  \n",
        "  return mid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhOGI3kRmAXI",
        "colab_type": "text"
      },
      "source": [
        "**Drawing points for every bounding box on the image :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ2WohP7ckzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function\n",
        "midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "\n",
        "#visualize image\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m9mvnNJmWDp",
        "colab_type": "text"
      },
      "source": [
        "#**Step 5(b) : Defining a function to compute the Eucleadean distance between two points or boxes in an image :**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oarPU8QBckuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "from scipy.spatial import distance\n",
        "def compute_distance(midpoints,num):\n",
        "  dist = np.zeros((num,num))\n",
        "  for i in range(num):\n",
        "    for j in range(i+1,num):\n",
        "      if i!=j:\n",
        "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
        "        dist[i][j]=dst\n",
        "  return dist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkrmOrqmph1",
        "colab_type": "text"
      },
      "source": [
        "**Computing the distance between every pair of points :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQfkzbiJckrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist= compute_distance(midpoints,num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sFw_0kQnHex",
        "colab_type": "text"
      },
      "source": [
        "**Defining a function that returns closest people on given proximity distance. Here, proximity distance refers to minimum distance between two people :**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_xNJIsEdA9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "def find_closest(dist,num,thresh):\n",
        "  p1=[]\n",
        "  p2=[]\n",
        "  d=[]\n",
        "  for i in range(num):\n",
        "    for j in range(i,num):\n",
        "      if( (i!=j) & (dist[i][j]<=thresh)):\n",
        "        p1.append(i)\n",
        "        p2.append(j)\n",
        "        d.append(dist[i][j])\n",
        "  return p1,p2,d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLX_sNs2nlLQ",
        "colab_type": "text"
      },
      "source": [
        "**Setting up a threshold for the proximity distance (say 100) :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcHIvxc2dBDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "thresh=20\n",
        "p1,p2,d=find_closest(dist,num,thresh)\n",
        "df = pd.DataFrame({\"p1\":p1,\"p2\":p2,\"dist\":d})\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIFaoYytobiH",
        "colab_type": "text"
      },
      "source": [
        "**Defining a function to change the color of closest people to red :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkkQFg8EdHax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_2_red(img,person,p1,p2):\n",
        "  risky = np.unique(p1+p2)\n",
        "  for i in risky:\n",
        "    x1,y1,x2,y2 = person[i]\n",
        "    _ = cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 2)  \n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m5tDYCRdHX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = change_2_red(img,person,p1,p2)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzm89W8oreq",
        "colab_type": "text"
      },
      "source": [
        "#**Final Step : Carrying out the similar set of steps on every frame of the video**#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3pKGeidHUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "names=os.listdir('frames/')\n",
        "names.sort(key=lambda f: int(re.sub('\\D', '', f)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN9a3FPIqNIo",
        "colab_type": "text"
      },
      "source": [
        "**Function that will cover all the steps we covered on each and every frame of the video :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSzxnOARee-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_closest_people(name,thresh):\n",
        "\n",
        "  img = cv2.imread('frames/'+name)\n",
        "  outputs = predictor(img)\n",
        "  classes=outputs['instances'].pred_classes.cpu().numpy()\n",
        "  bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "  ind = np.where(classes==0)[0]\n",
        "  person=bbox[ind]\n",
        "  midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "  num = len(midpoints)\n",
        "  dist= compute_distance(midpoints,num)\n",
        "  p1,p2,d=find_closest(dist,num,thresh)\n",
        "  img = change_2_red(img,person,p1,p2)\n",
        "  cv2.imwrite('frames/'+name,img)\n",
        "  return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZTvujvrKQH",
        "colab_type": "text"
      },
      "source": [
        "**Identifying the closest people and changing the color to red :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrcnJQFqefIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "thresh=100\n",
        "_ = [find_closest_people(names[i],thresh) for i in tqdm(range(len(names))) ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AmxiJSUryWJ",
        "colab_type": "text"
      },
      "source": [
        "**Putting it all together in each and every frame of the video :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NsEo-zIfNxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "frames = os.listdir('frames/')\n",
        "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "\n",
        "frame_array=[]\n",
        "\n",
        "for i in range(len(frames)):\n",
        "\n",
        "  #reading each files\n",
        "  img = cv2.imread('frames/'+frames[i])\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  height, width, layers = img.shape\n",
        "  size = (width,height)\n",
        "  \n",
        "  #inserting the frames into image array\n",
        "  frame_array.append(img)\n",
        "                     \n",
        "out = cv2.VideoWriter('sampleOutput.mp4',cv2.VideoWriter_fourcc(*'DIVX'),25,size)\n",
        "\n",
        "for i in range(len(frame_array)):\n",
        "  out.write(frame_array[i])\n",
        "out.release()  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}