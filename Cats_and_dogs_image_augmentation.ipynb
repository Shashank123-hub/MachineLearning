{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats and dogs image augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMi/ExfH67TPoDJW9qchmAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank123-hub/MachineLearning/blob/master/Cats_and_dogs_image_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp1hA3NZwsSd",
        "colab_type": "text"
      },
      "source": [
        "# **Model number 2 :**\n",
        "\n",
        "Here, we will make a convolutional neural network to identify and classify image of cats and dogs. For this, we will use the training set from the google ***Kaggle*** trainng set wich almost consists of around 6 million images of dogs and cats of which 25,000 are available.\n",
        "\n",
        "Also, we will use image augmentation to resolve the  issue of ***overfitting*** by issuing a ***validation set*** along with the training set which will simultaneously check for the accuracy of the neural network in recogonizing the images furthur reducing the phenomena of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF5ATJCvyyiL",
        "colab_type": "text"
      },
      "source": [
        "# **Title : Cats & Dogs image classification with image augmentation**\n",
        "\n",
        "# **Step 1 : Importing all dependancies**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB6JNSUawn9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf  #Importing tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtkkdWgzc_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #Importing the Imagedatagenerator class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDa5NM5szc8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os          #Importing other dependancies like numpy and matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb2jR1u0BVl",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2 : Loading the data**\n",
        "\n",
        "Here, we are simply downloading the dataset to train our model.\n",
        "Our dataset here will be downloaded from Kaggle which is provided by Microsoft research.\n",
        "\n",
        "The *ImageDataGenerator* simply reads the data from the disk. So, we simply need to download the dataset from the URL and unzip in the colab filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiGQDtov0Bmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin = _URL extract= )  #directory where the files will be extracted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gddiTdAu15_H",
        "colab_type": "text"
      },
      "source": [
        "# **Step 3 : Defining the data**\n",
        "\n",
        "Here, we assign variables to our dataset and define the training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jDJbBUb16Zm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered') #defining the base directory\n",
        "train_dir = os.path.join(base_dir , 'train')\n",
        "validation_dir = os.path.join(base_dir , 'validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwfuNKJT25gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats') #directory with the training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs') #directory with the training dog pictures\n",
        "validation_cats_dir = os.path.join(Validation_dir, 'cats') #directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs') #directory woth our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCMqNR4F25_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tra = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tra = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tra + num_dogs_tra\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_V4blal26DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tra)\n",
        "print('total training dog images', num_dogs_tra)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dog_val)\n",
        "\n",
        "print('total training images:', total_train)\n",
        "print('total validation images:', total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx_Kffcu6qSn",
        "colab_type": "text"
      },
      "source": [
        "# **Step 4 : Setting model parameters**\n",
        "\n",
        "Here, we are simply defining the shape of our images and the batch size for our dataset.\n",
        " \n",
        "After defining this, the ***flow_from_directory*** method will load images in the disk and will apply rescaling and resizing into required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlu_lvuQ7uSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "IMG_SHAPE = 150 # Our training data consists od images with width of 150 pixels and the height of 150 pixels."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LlbYf299bnw",
        "colab_type": "text"
      },
      "source": [
        "# **Step 4 : Data Augmentation**\n",
        "\n",
        "This is the necessary step to avoid the problem of *overfitting* in the given neural network model. Overfitting refers to the problem where our model begins to learn the given training data after and training and performs poorly in the test dataset.\n",
        "\n",
        "The goal is at the training time, your model will never see the exact picture twice. This exposes the model to more aspects od the data, allowing it to generalize better among the different dataset. \n",
        "\n",
        "What Image Augmentation basically does is that is takes the pcitures and apllying different transformations to it several times so that our modes is exposed to different dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23fKxn139b2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The below function will plot the images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize = (20,20))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img)\n",
        "    plt.tight_layput()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXapzF6cA-sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 40,          #applying all the transformations to the training dataset\n",
        "    width_shift_range = 0.2,      #Rotation,zooming,flipping,scaling etc.\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size = BATCH_SIZE,\n",
        "                                                     directory = train_dir,\n",
        "                                                     shuffle= True,\n",
        "                                                     target_size = (IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode = 'binary')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIqGeEFyCqAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-32NJ9DbD7Q_",
        "colab_type": "text"
      },
      "source": [
        "# **Step 4(a) : Creating validation data generator**\n",
        "\n",
        "Generally, we only apply data augmentation to our training examples. In this case, we are only rescaling or validation images and cnverting them into batches into ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-dlZEgKE6aD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size = BATCH_SIZE,\n",
        "                                                 directory = validation_dir,\n",
        "                                                 target_size = (IMG_SHAPE,IMG_SHAPE),\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t2s8Hw4Fdck",
        "colab_type": "text"
      },
      "source": [
        "# **Step 5 : Define the model**\n",
        "\n",
        "This model consists of for convolutional blocks with a maxpool layer in each of them.\n",
        "\n",
        "Before the final dense layers, we are also applying a Droupout Probablity of 0.5. That means that 50% of the values in the dropout layer will be ste to zero which will enable to reduce overfitting.\n",
        "\n",
        "Then we will have a fully connected layer with 512 units with a ***relu*** activation function. Also, the model will output class probablities for two classes - dogs and cats - using ***softmax*** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkv0Nb0yFcn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)), #indicating the image of 150 pixels each in height and width with 3 denoting the specific RGB layers.\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #one of the four convolution block with max pool layer\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5), #dropout fucntion for each layer with 0.5 probability\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'), #fully connected layer with 512 units\n",
        "    tf.keras.layers.Dense(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhtP5b2uHhkj",
        "colab_type": "text"
      },
      "source": [
        "# **Step 6 : Compiling the model**\n",
        "\n",
        "We will use adam optimizer just like the previous neural network models.\n",
        "\n",
        "Since, we output a sofmax categorization, we'll use sparse_categorical_crossentropy as the loss function.And will also aplly the traing and validation accuracy on each epoch. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxAlReGCIO7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimize = 'adam',\n",
        "              loss=tf.keras.losses.SparseCategorialCrossentropy(from_logits=True),\n",
        "              metrices=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXRBVc_WIkk9",
        "colab_type": "text"
      },
      "source": [
        "# **Summarizing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyec7HyaIuZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i327JoqUI8gC",
        "colab_type": "text"
      },
      "source": [
        "# **Step 7 : Traing the model**\n",
        "\n",
        "Since , our batches are coming from a generator , we'll use ***fit_generator*** instead of ***fit***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Cr42vZ-I9Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=100\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epochs = int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs = epochs,\n",
        "    validation_data = val_data_gen,\n",
        "    validation_steps = int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmY5EPkJ6yd",
        "colab_type": "text"
      },
      "source": [
        "# **Final Step : Visualizing the results of our training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oAL9EuoJ7QF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('The accracy and loss plots of respective training and validation sets are given below.')\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}