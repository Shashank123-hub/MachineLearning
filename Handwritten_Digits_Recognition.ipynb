{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten_Digits_Recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOrVhIGEUgW59vVWAHnQ3PF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashank123-hub/MachineLearning/blob/master/Handwritten_Digits_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtXEkqL68lJW",
        "colab_type": "text"
      },
      "source": [
        "#**Project topic : Handwritten Digit Recognition**\n",
        "\n",
        "> The goal of this topic is to recognize handwritten digits by the user using the Convolution Neural Networks(CNNs).  \n",
        "We'll also build a GUI in which we can draw as well as recognize the digit right away.\n",
        "\n",
        "\n",
        "> Modules used in this projects are the **Keras library** for deep learning and the **Tkinter library** for building the GUI.\n",
        "\n",
        "> Also, the dataset used here is the **MNIST dataset**. It contains 60,000 images of handwritten digits from zero to nine and 10,000 images for testing. It has 10 different classes and the images are represented as 28*28 matrix with each cell contains with grayscale pixel value.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-R7aGJYPq8F",
        "colab_type": "text"
      },
      "source": [
        "#**Step 1 : Installing the dependancies and load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fNggriP8mZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "e6315366-8df5-4c03-cc00-b93479f8344d"
      },
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install pillow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.30.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (47.3.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.1.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting win32gui\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/75/7bed82934e51903f9d48b26b3996161bb2dce1731607b4bb7fd26003ed3e/win32gui-221.5.tar.gz (605kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 5.3MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.6/dist-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmp7p8m2ymd Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ffd0rORsmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "f6a6e42d-992a-44a8-cf46-3886ef91a42d"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "#Splitting the data between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhGqRMJY8ml7",
        "colab_type": "text"
      },
      "source": [
        "#**Step 2 : Preprocess the data**\n",
        "\n",
        "> This step primarily involves making our data ready for the neural network to be trained. The dimension of the training data is (60000,28,28) and the CNN model will require one more dimension to the shape (60000,28,28,1).    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0aCwyfu8cVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "b2846c34-4c72-4f91-acc4-7aa1033fcd9b"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=None)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=None)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "print('x_train shape/Input dataset shape:', x_train.shape)\n",
        "print('Train samples :',x_train.shape[0])\n",
        "print('Test samples :',x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape/Input dataset shape: (60000, 28, 28, 1)\n",
            "Train samples : 60000\n",
            "Test samples : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXab5EOX8tSW",
        "colab_type": "text"
      },
      "source": [
        "#**Step 3 : Creating the model**\n",
        "\n",
        "> Our model simply consist of convolutional and pooling layer with dropouts for each layer.\n",
        "\n",
        "\n",
        "\n",
        "> The optimizer used here is the **Adadelta optimizer**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht6cdN888tz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = input_shape)) #a convolutional neural layer\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))  #another CNN layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))  #pooling layer downsampling the images     \n",
        "model.add(Dropout(0.25))  #dropout for the above layer\n",
        "model.add(Flatten())  #flatten layer to convert data into 1-D/flattening the data\n",
        "model.add(Dense(256, activation='relu'))  #third dense layer\n",
        "model.add(Dropout(0.5))  #dropout for the above layer\n",
        "model.add(Dense(num_classes, activation='softmax'))  #final dense layer  \n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy, \n",
        "optimizer = keras.optimizers.Adadelta() ,metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BYzOGIv8uPT",
        "colab_type": "text"
      },
      "source": [
        "#**Step 4 : Training the compiled model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q2se5m48udg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "583a8f64-ab8e-4a49-b41b-4e2dc806257c"
      },
      "source": [
        "hist = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "print(\"The model has been successfully trained\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.2201 - accuracy: 0.9311 - val_loss: 0.0571 - val_accuracy: 0.9810\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 161s 3ms/step - loss: 0.0712 - accuracy: 0.9782 - val_loss: 0.0439 - val_accuracy: 0.9850\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0522 - accuracy: 0.9842 - val_loss: 0.0330 - val_accuracy: 0.9895\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.0280 - val_accuracy: 0.9906\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0339 - accuracy: 0.9893 - val_loss: 0.0276 - val_accuracy: 0.9906\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 0.0273 - val_accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0247 - val_accuracy: 0.9918\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0240 - val_accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0249 - val_accuracy: 0.9917\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0257 - val_accuracy: 0.9921\n",
            "The model has successfully trained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1pBF7twpUjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b64ba335-6081-4a20-c7b4-3c3b50e6ab62"
      },
      "source": [
        "model.save('HDRmodel.h5')\n",
        "print('Saving the model as HDRmodel.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving the model as HDRmodel.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCIqUd88uqZ",
        "colab_type": "text"
      },
      "source": [
        "#**Step 5 : Evaluating the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9yrCeF78u-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0049690d-1a71-4417-838b-2915b78d27b4"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose =0)\n",
        "print('Loss percentage = ', score[0]*100)\n",
        "print('Accuracy percentage = ', score[1]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss percentage =  2.5740840514458614\n",
            "Accuracy percentage =  99.21000003814697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PPYBz0irqFE",
        "colab_type": "text"
      },
      "source": [
        "#**Step 6 : Creating GUI for prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3EO5sxI3mtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "74a295d4-e5fe-41ac-87e0-84e4ef1b95eb"
      },
      "source": [
        "!pip install win32\n",
        "from keras.models import load_model\n",
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "#import win32gui\n",
        "from PIL import ImageGrab, Image\n",
        "import numpy as np\n",
        "\n",
        "model = load_model('HDRmodel.h5')\n",
        "def predict_digit(img):\n",
        "    #resize image to 28x28 pixels\n",
        "    img = img.resize((28,28))\n",
        "    #convert rgb to grayscale\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img)\n",
        "    #reshaping to support our model input and normalizing\n",
        "    img = img.reshape(1,28,28,1)\n",
        "    img = img/255.0\n",
        "    #predicting the class\n",
        "    res = model.predict([img])[0]\n",
        "    return np.argmax(res), max(res)\n",
        "class App(tk.Tk):\n",
        "    def __init__(self):\n",
        "        tk.Tk.__init__(self)\n",
        "        self.x = self.y = 0\n",
        "        # Creating elements\n",
        "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
        "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
        "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
        "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
        "        # Grid structure\n",
        "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
        "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
        "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
        "        self.button_clear.grid(row=1, column=0, pady=2)\n",
        "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
        "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
        "    def clear_all(self):\n",
        "        self.canvas.delete(\"all\")\n",
        "    def classify_handwriting(self):\n",
        "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
        "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
        "        im = ImageGrab.grab(rect)\n",
        "        digit, acc = predict_digit(im)\n",
        "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
        "    def draw_lines(self, event):\n",
        "        self.x = event.x\n",
        "        self.y = event.y\n",
        "        r=8\n",
        "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
        "app = App()\n",
        "mainloop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement win32 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for win32\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ac7742e63553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtkinter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#import win32gui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageGrab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageGrab.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"darwin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ImageGrab is macOS and Windows only\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: ImageGrab is macOS and Windows only",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}